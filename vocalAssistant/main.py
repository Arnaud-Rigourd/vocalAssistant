import json
import logging
import os
from functools import lru_cache
from pathlib import Path

import openai
import requests as requests
from dotenv import load_dotenv
from elevenlabs import generate, play
from tinydb import TinyDB

load_dotenv()

logging.basicConfig(
    level=logging.DEBUG,
    filename='app.log',
    filemode='w',
    format="%(asctime)s - %(levelname)s : %(message)s",
)

CUR_DIR = Path(__file__).resolve().parent
db = TinyDB(f"{CUR_DIR}/history.json", indent=4)
chats = db.table("Chats")


def ask_chatbot(instructions) -> int:
    print("Thinking ðŸ¤”...")
    gpt_answer = interact_with_GPT(instructions)
    logging.debug("interact_with_GPT: success")
    print("Warming up the voice ðŸŽ¤...")
    audio = _generate_audio_from_text(gpt_answer[6:])
    logging.debug("_generate_audio_from_text: success")
    print(gpt_answer)
    play(audio)
    return _get_remaining_characters()


@lru_cache
def _get_initial_GPT_prompt() -> str:
    """Set up the intial GPT prompt"""
    initial_prompt = "Tu es un chatbot dont le rÃ´le est de m'assister dans mes problÃ©matiques quotidiennes. Tu es notamment spÃ©cialisÃ© sur le langage Python depuis plus de 20 ans et tu as une connaissance parfaite de toutes les librairies, modules et packages permettant d'optimiser les fonctions que tu me proposes pour rÃ©pondre Ã  mes demandes. Tu agis en tant que consultant perfectionniste et a pour but de toujours apporter la rÃ©ponse la plus prÃ©cise. Pour atteindre cet objectif, tu n'hÃ©sites pas Ã  me poser des questions si ma demande n'est pas assez claire pour que tu puisses y rÃ©pondre parfaitement. Je vais t'envoyer des prompts en franÃ§ais, je veux que tu me rÃ©pondes EN ANGLAIS Ã  chaque fois. Ne rÃ©ponds pas Ã  ce message qui a pour but de t'indiquer ton role. RÃ©ponds Ã  partir du prochain prompt qui te sera envoyÃ©. Tes rÃ©ponse ne doivent Ãªtres concises et ne doivent ABSOLUMENT PAS dÃ©passer les 10000 caractÃ¨res."

    return initial_prompt


def interact_with_GPT(instructions: str = None) -> str:
    """Send the use prompt to GPT3.5-turbo API and return the response"""
    openai.api_key = os.getenv("OPENAI_API_KEY")
    initial_prompt = _get_initial_GPT_prompt()

    if chats:
        chats.insert_multiple([
            {"role": "user", "content": instructions},
        ])
    else:
        chats.insert_multiple([
            {"role": "system", "content": initial_prompt},
            {"role": "user", "content": instructions},
        ])

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=chats.all(),
        temperature=1
    )

    reply = response['choices'][0]['message']['content']
    chats.insert({"role": "assistant", "content": reply})

    return f"GPT : {reply}"


def _generate_audio_from_text(gpt_answer: str) -> bytes:
    try:
        audio = generate(
            text=gpt_answer,
            api_key=os.getenv('ELEVEN_API_KEY'),
            voice="Elli",
            model="eleven_monolingual_v1"
        )
        logging.debug("_generate_audio_from_text: call to Eleven Labs API passed")
    except:
        logging.error("Call to Eleven Labs API failed")

    return audio


def _get_remaining_characters() -> int:
    url = "https://api.elevenlabs.io/v1/user/subscription"

    headers = {
        "Accept": "application/json",
        "xi-api-key": os.getenv('ELEVEN_API_KEY')
    }

    response = requests.get(url, headers=headers)

    response_to_dict = json.loads(response.text)
    remaining_characters = 10_000 - response_to_dict["character_count"]

    return f"remaining characters: {remaining_characters}"


if __name__ == '__main__':
    instructions = input("Parlez : ")
    while True:
        if "fin de la discussion" in instructions.lower():
            break
        response = ask_chatbot(instructions)
        print(response)
        instructions = input("Parlez : ")

    chats.truncate()
